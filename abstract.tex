%!TEX root=thesis.tex

Semantic segmentation of satellite images is an important task as it has a wide range of practical applications, such as land cover mapping, poolution monitoring, deforestation detection and economic assessment. With the rise of deep learning, semantic segmentation models have been built using the convolutional neural network for many years. CNNs have proven to be really good at capturing local features due to its convolution layer. However, the same convolution layer limits the network from capturing the global context. Recently, Transformers, a network that was originally designed for processing texts were adopted by the field of computer vision and has shown a lot of potential to computer vision task such as semantic segmentation. Unlike CNN, Transformer has the ability to capture both local and global features.

For FYP 1, we utilized UNet-like Transformer (UNetFormer) that is made up of a CNN-based encoder and Transformer-based decoder for semantic segmentation of satellite images to get an initial result. We also trained a U-Net, a purely CNN-based encoder-decoder network using the same dataset to get a comparison with the result obtained from UNetFormer.

The dataset chosen for this project is the LoveDA dataset which contains 5987 High Spatial Resolution (HSR )images with 166768 annotated pixels from three different cities in China.

Result

We observed that the model produced by the UNetFormer is very large which makes it unsuitable for real-world application. We included a few suggestions to compress the model while maintaining its performance. This would be one of the task in FYP 2.
