%!TEX root=thesis.tex

Semantic segmentation of satellite pictures is a crucial task since it has many practical uses, including mapping land cover, detecting deforestation, monitoring pollution, and assessing economic activity. CNNss have been used to create semantic segmentation models for a long time prior to the development offormersing. CNNs have proven to be really good at capturing local features but limited when capturing the global features. Recently, Transformers, a network that was originally designed for processing texts were adopted by the field of computer vision and has shown a lot of potential to computer vision task such as semantic segmentation. Unlike CNN, Transformer has the ability to capture both local and global features. For FYP 1, we utilized UNet-like Transformer (UNetFormer) that has a CNN encoder and Transformer decoder for semantic segmentation of satellite images to get an baselineresult. We also trained  U-Net, a purely CNN-based encoder-decoder network using the same dataset for comparison purpose. The dataset chosen for this project is the LoveDA dataset which contains 5987 High Spatial Resolution (HSR )images with 166768 labelled pixels.

U-Net gave an mIoU of 33.6\% and the UNetFormer gave an mIoU gave an mIoU of 72.5\%. U-Net has only 2.4 million parameters compared to 11.2 million on the UNetFormer.

