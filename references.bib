
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% APPLICATIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Yuan2020DeepLI,
  title={Deep learning in environmental remote sensing: Achievements and challenges},
  author={Qiangqiang Yuan and Huanfeng Shen and Tongwen Li and Zhiwei Li and Shuwen Li and Yun Jiang and Hongzhang Xu and Weiwei Tan and Qianqian Yang and Jiwen Wang and Jianhao Gao and Liang-pei Zhang},
  journal={Remote Sensing of Environment},
  year={2020},
  volume={241},
  pages={111716}
}

@article{DBLP:journals/corr/Thoma16a,
  author    = {Martin Thoma},
  title     = {A Survey of Semantic Segmentation},
  journal   = {CoRR},
  volume    = {abs/1602.06541},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.06541},
  eprinttype = {arXiv},
  eprint    = {1602.06541},
  timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Thoma16a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{edseee.864274320181101,
Author = {Talal, Mina and Panthakkan, Alavikunhu and Mukhtar, Husameldin and Mansoor, Wathiq and Almansoori, Saeed and Ahmad, Hussain Al},
ISSN = {978-1-7281-0257-3},
Journal = {2018 International Conference on Signal Processing and Information Security (ICSPIS), Signal Processing and Information Security (ICSPIS), 2018 International Conference on},
Keywords = {Communication, Networking and Broadcast Technologies, Computing and Processing, Signal Processing and Analysis, Image segmentation, Semantics, Satellites, Signal processing algorithms, Training, Remote sensing, Neural networks, Deep learning, semantic segmentation, neural network, satellite images, remote sensing},
Pages = {1 - 4},
Title = {Detection of Water-Bodies Using Semantic Segmentation.},
URL = {https://go.openathens.net/redirector/mmu.edu.my?url={UrlEncode(https://search.ebscohost.com/login.aspx?direct=true&AuthType=shib&db=edseee&AN=edseee.8642743&site=eds-live)},
Year = {2018},
}}

@article{edseee.988427220220717,
Author = {Leach, Nicholas R. and Popien, Philip and Goodman, Maxwell C. and Tellman, Beth},
ISSN = {978-1-6654-2792-0},
Journal = {IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium, Geoscience and Remote Sensing Symposium, IGARSS 2022 - 2022 IEEE International},
Keywords = {Aerospace, Components, Circuits, Devices and Systems, Computing and Processing, Engineered Materials, Dielectrics and Plasmas, Fields, Waves and Electromagnetics, Geoscience, Photonics and Electrooptics, Power, Energy and Industry Applications, Signal Processing and Analysis, Biological system modeling, Small satellites, Forestry, Radiometry, Sensors, Convolutional neural networks, Floods, flood mapping, convolutional neural network, Random Forest, remote sensing, Sentinel-1, image segmentation},
Pages = {314 - 317},
Title = {Leveraging convolutional neural networks for semantic segmentation of global floods with PlanetScope imagery.},
URL = {https://go.openathens.net/redirector/mmu.edu.my?url={UrlEncode(https://search.ebscohost.com/login.aspx?direct=true&AuthType=shib&db=edseee&AN=edseee.9884272&site=eds-live)},
Year = {2022},
}}

@INPROCEEDINGS{9554290,
  author={Pandey, Abhinav and Kumar, Devesh and Chakraborty, Debarati B.},
  booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, 
  title={Soil Type Classification from High Resolution Satellite Images with Deep CNN}, 
  year={2021},
  volume={},
  number={},
  pages={4087-4090},
  doi={10.1109/IGARSS47720.2021.9554290}
  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DATASETS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@Article{potsdam-vaihingen,
AUTHOR = {Rottensteiner, F. and Sohn, G. and Jung, J. and Gerke, M. and Baillard, C. and Benitez, S. and Breitkopf, U.},
TITLE = {THE ISPRS BENCHMARK ON URBAN OBJECT CLASSIFICATION AND 3D BUILDING RECONSTRUCTION},
JOURNAL = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
VOLUME = {I-3},
YEAR = {2012},
PAGES = {293--298},
URL = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/I-3/293/2012/},
DOI = {10.5194/isprsannals-I-3-293-2012}
}

@inproceedings{loveda,
author = {Wang, Junjue and Zheng, Zhuo and Ma, Ailong and Lu, Xiaoyan and Zhong, Yanfei},
year = {2021},
month = {10},
pages = {},
title = {LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic Segmentation}
}

@article{GID2020,
  title={Land-cover classification with high-resolution remote sensing images using transferable deep models},
  author={Tong, Xin-Yi and Xia, Gui-Song and Lu, Qikai and Shen, Huanfeng and Li, Shengyang and You, Shucheng and Zhang, Liangpei},
  journal={Remote Sensing of Environment},
  volume={237},
  pages={111322},
  year={2020}
}

@article{deep-globe,
  author    = {Ilke Demir and
               Krzysztof Koperski and
               David Lindenbaum and
               Guan Pang and
               Jing Huang and
               Saikat Basu and
               Forest Hughes and
               Devis Tuia and
               Ramesh Raskar},
  title     = {DeepGlobe 2018: {A} Challenge to Parse the Earth through Satellite
               Images},
  journal   = {CoRR},
  volume    = {abs/1805.06561},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.06561},
  eprinttype = {arXiv},
  eprint    = {1805.06561},
  timestamp = {Thu, 20 Feb 2020 18:58:02 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-06561.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{landcoverai,
    author = {Boguszewski, Adrian and Batorski, Dominik and Ziemba-Jankowska, Natalia and Dziedzic, Tomasz and Zambrzycka, Anna},
    title = {LandCover.ai: Dataset for Automatic Mapping of Buildings, Woodlands, Water and Roads from Aerial Imagery},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month = {June},
    year = {2021},
    pages = {1102-1110}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CNN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@Article{multi-attention-unet,
AUTHOR = {Sun, Yu and Bi, Fukun and Gao, Yangte and Chen, Liang and Feng, Suting},
TITLE = {A Multi-Attention UNet for Semantic Segmentation in Remote Sensing Images},
JOURNAL = {Symmetry},
VOLUME = {14},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {906},
URL = {https://www.mdpi.com/2073-8994/14/5/906},
ISSN = {2073-8994},
}

@Article{improved-unet,
AUTHOR = {Fan, Xiangsuo and Yan, Chuan and Fan, Jinlong and Wang, Nayi},
TITLE = {Improved U-Net Remote Sensing Classification Algorithm Fusing Attention and Multiscale Features},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {15},
ARTICLE-NUMBER = {3591},
URL = {https://www.mdpi.com/2072-4292/14/15/3591},
ISSN = {2072-4292},
DOI = {10.3390/rs14153591}
}

@InProceedings{attention-unet-road,
author="Tao, Minyu
and Ding, Zhiming
and Cao, Yang",
editor="Meng, Xiaofeng
and Xie, Xing
and Yue, Yang
and Ding, Zhiming",
title="Attention U-Net for Road Extraction in Remote Sensing Images",
booktitle="Spatial Data and Intelligence",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="153--164",
abstract="The reliable road network plays a vital role in many applications. Owing to the development of remote sensing technology and the success of deep learning in computer vision, automatic road extraction from remote sensing images is a research hotspot in recent years. However, due to the complicated image background and special road structure, the results of automatic road extraction are still far from perfect. In this paper, we propose a road segmentation network that is designed based on improved U-Net, which contains an encoder and a decoder. First, the recurrent criss-cross attention module (CCA) is introduced into the encoder to obtain long-range contextual dependencies with a relatively small number of computations and parameters, which results in better understanding and expression of image information. Second, we propose the attention-based multi-scale feature fusion module (AMS) to resolve the problem of different shapes and widths of the roads, which is placed between the encoder and decoder and uses attention mechanisms to guide multi-scale information fusion. Experimental on the Massachusetts Roads Dataset show that the proposed method achieves better performance in road extraction than other methods in terms of precision, recall, F1-score, and accuracy.",
isbn="978-3-030-69873-7"
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TRADITIONAL METHODS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{YU201882,
title = {Methods and datasets on semantic segmentation: A review},
journal = {Neurocomputing},
volume = {304},
pages = {82-103},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.03.037},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218304077},
author = {Hongshan Yu and Zhengeng Yang and Lei Tan and Yaonan Wang and Wei Sun and Mingui Sun and Yandong Tang},
keywords = {Semantic segmentation, Convolutional neural network, Markov random fields, Weakly supervised method, 3D point clouds labeling},
abstract = {Semantic segmentation, also called scene labeling, refers to the process of assigning a semantic label (e.g. car, people, and road) to each pixel of an image. It is an essential data processing step for robots and other unmanned systems to understand the surrounding scene. Despite decades of efforts, semantic segmentation is still a very challenging task due to large variations in natural scenes. In this paper, we provide a systematic review of recent advances in this field. In particular, three categories of methods are reviewed and compared, including those based on hand-engineered features, learned features and weakly supervised learning. In addition, we describe a number of popular datasets aiming for facilitating the development of new segmentation algorithms. In order to demonstrate the advantages and disadvantages of different semantic segmentation models, we conduct a series of comparisons between them. Deep discussions about the comparisons are also provided. Finally, this review is concluded by discussing future directions and challenges in this important field of research.}
}

@article{SIFT,
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  acmid = {996342},
  added-at = {2012-11-08T15:54:11.000+0100},
  address = {Hingham, MA, USA},
  author = {Lowe, David G.},
  biburl = {https://www.bibsonomy.org/bibtex/2c9984d3a783a48553018a518847f6657/daill},
  description = {Distinctive Image Features from Scale-Invariant Keypoints},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  interhash = {a1c2b94c96ee2ef15ef53e73b7fd9a8d},
  intrahash = {c9984d3a783a48553018a518847f6657},
  issn = {0920-5691},
  issue_date = {November 2004},
  journal = {Int. J. Comput. Vision},
  keywords = {feature sift},
  month = nov,
  number = 2,
  numpages = {20},
  pages = {91--110},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2012-11-08T15:54:11.000+0100},
  title = {Distinctive Image Features from Scale-Invariant Keypoints},
  url = {http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94},
  volume = 60,
  year = 2004
}

@book{markovbook,
  title     = "Markov Random Fields for Vision and Image Processing",
  author    = "Andrew Blake and Pushmeet Kohli and Carsten Rother",
  year      = 2011,
  publisher = "MIT Press",
  address   = "Cambridge, Massachusetts"
}

@article{crf-semantic,
  author    = {Marvin T. T. Teichmann and
               Roberto Cipolla},
  title     = {Convolutional CRFs for Semantic Segmentation},
  journal   = {CoRR},
  volume    = {abs/1805.04777},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.04777},
  eprinttype = {arXiv},
  eprint    = {1805.04777},
  timestamp = {Mon, 13 Aug 2018 16:47:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-04777.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Schroff2008ObjectCS,
  title={Object Class Segmentation using Random Forests},
  author={Florian Schroff and Antonio Criminisi and Andrew Zisserman},
  booktitle={BMVC},
  year={2008}
}

%%%%%%%%%%%%%%%%%%%%%Convolutional Neural Network%%%%%%%%%%%%%%%%%%%%%%

@INPROCEEDINGS{7298965,

  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},

  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Fully convolutional networks for semantic segmentation}, 

  year={2015},

  volume={},

  number={},

  pages={3431-3440},

  doi={10.1109/CVPR.2015.7298965}}

@article{unet,
  author    = {Olaf Ronneberger and
               Philipp Fischer and
               Thomas Brox},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal   = {CoRR},
  volume    = {abs/1505.04597},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.04597},
  eprinttype = {arXiv},
  eprint    = {1505.04597},
  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{enlarge-receptive-field,
author = {Liu, Weide and Zhang, Chi and Lin, Guosheng and Liu, Fayao},
title = {CRCNet: Few-Shot Segmentation with Cross-Reference and Region–Global Conditional Networks},
year = {2022},
issue_date = {Dec 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {130},
number = {12},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-022-01677-7},
doi = {10.1007/s11263-022-01677-7},
abstract = {Few-shot segmentation aims to learn a segmentation model that can be generalized to novel classes with only a few training images. In this paper, we propose a Cross-Reference and Local–Global Conditional Networks (CRCNet) for few-shot segmentation. Unlike previous works that only predict the query image’s mask, our proposed model concurrently makes predictions for both the support image and the query image. Our network can better find the co-occurrent objects in the two images with a cross-reference mechanism, thus helping the few-shot segmentation task. To further improve feature comparison, we develop a local-global conditional module to capture both global and local relations. We also develop a mask refinement module to refine the prediction of the foreground regions recurrently. Experiments on the PASCAL VOC 2012, MS COCO, and FSS-1000 datasets show that our network achieves new state-of-the-art performance.},
journal = {Int. J. Comput. Vision},
month = {sep},
pages = {3140–3157},
numpages = {18},
keywords = {Semantic segmentation, Few shot learning}
}

@article{feature-pyramid,
  author    = {Hengshuang Zhao and
               Jianping Shi and
               Xiaojuan Qi and
               Xiaogang Wang and
               Jiaya Jia},
  title     = {Pyramid Scene Parsing Network},
  journal   = {CoRR},
  volume    = {abs/1612.01105},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.01105},
  eprinttype = {arXiv},
  eprint    = {1612.01105},
  timestamp = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZhaoSQWJ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{abcnet,
title = {ABCNet: Attentive bilateral contextual network for efficient semantic segmentation of Fine-Resolution remotely sensed imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {181},
pages = {84-98},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621002379},
author = {Rui Li and Shunyi Zheng and Ce Zhang and Chenxi Duan and Libo Wang and Peter M. Atkinson},
keywords = {Semantic Segmentation, Attention Mechanism, Bilateral Architecture, Convolutional Neural Network, Deep Learning}
}

%%%%%%%%%%%%%%%%%%%%%Lit Review%%%%%%%%%%%%%%%%%%%%

@article{weakly-supervised-semantic,
  author    = {Michael Schmitt and
               Jonathan Prexl and
               Patrick Ebel and
               Lukas Liebel and
               Xiao Xiang Zhu},
  title     = {Weakly Supervised Semantic Segmentation of Satellite Images for Land
               Cover Mapping - Challenges and Opportunities},
  journal   = {CoRR},
  volume    = {abs/2002.08254},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.08254},
  eprinttype = {arXiv},
  eprint    = {2002.08254},
  timestamp = {Tue, 08 Mar 2022 10:14:57 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-08254.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{benchmarking-scaling,
  author    = {Ioannis Papoutsis and
               Nikolaos{-}Ioannis Bountos and
               Angelos Zavras and
               Dimitrios Michail and
               Christos Tryfonopoulos},
  title     = {Efficient deep learning models for land cover image classification},
  journal   = {CoRR},
  volume    = {abs/2111.09451},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.09451},
  eprinttype = {arXiv},
  eprint    = {2111.09451},
  timestamp = {Mon, 22 Nov 2021 16:44:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-09451.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{unetformer,
  author    = {Libo Wang and
               Shenghui Fang and
               Ce Zhang and
               Rui Li and
               Chenxi Duan},
  title     = {Efficient Hybrid Transformer: Learning Global-local Context for Urban
               Sence Segmentation},
  journal   = {CoRR},
  volume    = {abs/2109.08937},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.08937},
  eprinttype = {arXiv},
  eprint    = {2109.08937},
  timestamp = {Mon, 11 Oct 2021 13:51:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-08937.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{transformer-meet-conv,
  author    = {Libo Wang and
               Rui Li and
               Dongzhi Wang and
               Chenxi Duan and
               Teng Wang and
               Xiaoliang Meng},
  title     = {Transformer Meets Convolution: {A} Bilateral Awareness Net-work for
               Semantic Segmentation of Very Fine Resolution Ur-ban Scene Images},
  journal   = {CoRR},
  volume    = {abs/2106.12413},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.12413},
  eprinttype = {arXiv},
  eprint    = {2106.12413},
  timestamp = {Mon, 11 Oct 2021 13:51:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-12413.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{a-novel-transformer,

  author={Wang, Libo and Li, Rui and Duan, Chenxi and Zhang, Ce and Meng, Xiaoliang and Fang, Shenghui},

  journal={IEEE Geoscience and Remote Sensing Letters}, 

  title={A Novel Transformer Based Semantic Segmentation Scheme for Fine-Resolution Remote Sensing Images}, 

  year={2022},

  volume={19},

  number={},

  pages={1-5},

  doi={10.1109/LGRS.2022.3143368}}

@misc{advancing-plain-vision-transformer,
  doi = {10.48550/ARXIV.2208.03987},
  
  url = {https://arxiv.org/abs/2208.03987},
  
  author = {Wang, Di and Zhang, Qiming and Xu, Yufei and Zhang, Jing and Du, Bo and Tao, Dacheng and Zhang, Liangpei},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Advancing Plain Vision Transformer Towards Remote Sensing Foundation Model},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@ARTICLE{multi-attention-network,

  author={Li, Rui and Zheng, Shunyi and Zhang, Ce and Duan, Chenxi and Su, Jianlin and Wang, Libo and Atkinson, Peter M.},

  journal={IEEE Transactions on Geoscience and Remote Sensing}, 

  title={Multiattention Network for Semantic Segmentation of Fine-Resolution Remote Sensing Images}, 

  year={2022},

  volume={60},

  number={},

  pages={1-13},

  doi={10.1109/TGRS.2021.3093977}}



@article{linear-attention-mechanism,
  author    = {Rui Li and
               Jianlin Su and
               Chenxi Duan and
               Shunyi Zheng},
  title     = {Linear Attention Mechanism: An Efficient Attention for Semantic Segmentation},
  journal   = {CoRR},
  volume    = {abs/2007.14902},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.14902},
  eprinttype = {arXiv},
  eprint    = {2007.14902},
  timestamp = {Mon, 11 Oct 2021 13:51:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-14902.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{A2-FPN,
  author    = {Rui Li and
               Shunyi Zheng and
               Chenxi Duan},
  title     = {Feature Pyramid Network with Multi-Head Attention for Semantic Segmentation
               of Fine-Resolution Remotely Sensed Images},
  journal   = {CoRR},
  volume    = {abs/2102.07997},
  year      = {2021},
  url       = {https://arxiv.org/abs/2102.07997},
  eprinttype = {arXiv},
  eprint    = {2102.07997},
  timestamp = {Mon, 11 Oct 2021 13:51:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-07997.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{attention-unet,
  author    = {Ozan Oktay and
               Jo Schlemper and
               Lo{\"{\i}}c Le Folgoc and
               Matthew C. H. Lee and
               Mattias P. Heinrich and
               Kazunari Misawa and
               Kensaku Mori and
               Steven G. McDonagh and
               Nils Y. Hammerla and
               Bernhard Kainz and
               Ben Glocker and
               Daniel Rueckert},
  title     = {Attention U-Net: Learning Where to Look for the Pancreas},
  journal   = {CoRR},
  volume    = {abs/1804.03999},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.03999},
  eprinttype = {arXiv},
  eprint    = {1804.03999},
  timestamp = {Tue, 17 Sep 2019 14:15:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-03999.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{lanet,

  author={Ding, Lei and Tang, Hao and Bruzzone, Lorenzo},

  journal={IEEE Transactions on Geoscience and Remote Sensing}, 

  title={LANet: Local Attention Embedding to Improve the Semantic Segmentation of Remote Sensing Images}, 

  year={2021},

  volume={59},

  number={1},

  pages={426-435},

  doi={10.1109/TGRS.2020.2994150}}


@article{unet-transformer,
title = {Adaptive enhanced swin transformer with U-net for remote sensing image segmentation},
journal = {Computers and Electrical Engineering},
volume = {102},
pages = {108223},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.108223},
url = {https://www.sciencedirect.com/science/article/pii/S004579062200461X},
author = {Xingjian Gu and Sizhe Li and Shougang Ren and Hengbiao Zheng and Chengcheng Fan and Huanliang Xu},
keywords = {Remote sensing, Semantic segmentation, Unet, Transformer, CNN},
abstract = {Semantic segmentation of remote sensing images often faces complex situations, such as variable scale objects, large intra-class differences, and imbalanced distribution among classes. Convolutional Neural Network (CNN) based models have been widely used in remote sensing image segmentation tasks for its powerful feature extraction capability. Due to intrinsic locality of CNN architectures, it is difficult to understand the long-range dependencies among image patches. Recently, the transformer leverages long-range dependencies and performs well in computer vision tasks. To take advantages of both CNN and Transformer, a novel Adaptive Enhanced Swin Transformer with U-Net (AESwin-UNet) is proposed for remote sensing segmentation. AESwin-UNet uses a hybrid Transformer-based U-type Encoder-Decoder architecture with skip connections to extract local and global semantic features. Specifically, the Enhanced Swin Transformer (E-Swin Transformer) contains Enhanced Multi-head Self-Attention and Deformable Adaptive Patch Merging layer in encoder. A symmetric cascaded decoder is designed for up-sampling to obtain higher resolution feature maps. Experiments on two public benchmark datasets, WHDLD and LoveDA, demonstrate that the proposed AESwin-UNet performs well in semantic segmentation.}
}

@inproceedings{restlite,
title={ResT: An Efficient Transformer for Visual Recognition},
author={Qinglong Zhang and Yu-bin Yang},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=6Ab68Ip4Mu}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%TRANSFORMERS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{detr,
  author    = {Nicolas Carion and
               Francisco Massa and
               Gabriel Synnaeve and
               Nicolas Usunier and
               Alexander Kirillov and
               Sergey Zagoruyko},
  title     = {End-to-End Object Detection with Transformers},
  journal   = {CoRR},
  volume    = {abs/2005.12872},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.12872},
  eprinttype = {arXiv},
  eprint    = {2005.12872},
  timestamp = {Thu, 28 May 2020 17:38:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-12872.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{learnregionfeat,
  author    = {Jiayuan Gu and
               Han Hu and
               Liwei Wang and
               Yichen Wei and
               Jifeng Dai},
  title     = {Learning Region Features for Object Detection},
  journal   = {CoRR},
  volume    = {abs/1803.07066},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.07066},
  eprinttype = {arXiv},
  eprint    = {1803.07066},
  timestamp = {Thu, 26 Nov 2020 07:56:57 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-07066.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{regionnet++,
 author = {Chi, Cheng and Wei, Fangyun and Hu, Han},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {13564--13574},
 publisher = {Curran Associates, Inc.},
 title = {RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder},
 url = {https://proceedings.neurips.cc/paper/2020/file/9d684c589d67031a627ad33d59db65e5-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{swin-v1,
  author    = {Ze Liu and
               Yutong Lin and
               Yue Cao and
               Han Hu and
               Yixuan Wei and
               Zheng Zhang and
               Stephen Lin and
               Baining Guo},
  title     = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  journal   = {CoRR},
  volume    = {abs/2103.14030},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.14030},
  eprinttype = {arXiv},
  eprint    = {2103.14030},
  timestamp = {Thu, 19 May 2022 16:00:58 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-14030.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{swin-v2,
  author    = {Ze Liu and
               Han Hu and
               Yutong Lin and
               Zhuliang Yao and
               Zhenda Xie and
               Yixuan Wei and
               Jia Ning and
               Yue Cao and
               Zheng Zhang and
               Li Dong and
               Furu Wei and
               Baining Guo},
  title     = {Swin Transformer {V2:} Scaling Up Capacity and Resolution},
  journal   = {CoRR},
  volume    = {abs/2111.09883},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.09883},
  eprinttype = {arXiv},
  eprint    = {2111.09883},
  timestamp = {Thu, 02 Dec 2021 15:54:22 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-09883.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{scaling-sparse,
  author    = {Carlos Riquelme and
               Joan Puigcerver and
               Basil Mustafa and
               Maxim Neumann and
               Rodolphe Jenatton and
               Andr{\'{e}} Susano Pinto and
               Daniel Keysers and
               Neil Houlsby},
  title     = {Scaling Vision with Sparse Mixture of Experts},
  journal   = {CoRR},
  volume    = {abs/2106.05974},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.05974},
  eprinttype = {arXiv},
  eprint    = {2106.05974},
  timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-05974.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{attention-is-all-you-need,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{16x16,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%%%%%%%%History of Deep Learning


@article{LeCunBoserDenkerEtAl89,
  added-at = {2008-09-16T23:39:07.000+0200},
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  biburl = {https://www.bibsonomy.org/bibtex/296c98d6adbcfbbea71385179ed056128/brian.mingus},
  description = {CCNLab BibTeX},
  interhash = {f532aea0ac3d409fbcae2c9ce8d5d1a2},
  intrahash = {96c98d6adbcfbbea71385179ed056128},
  journal = {Neural Computation},
  keywords = {nnets},
  pages = {541-551},
  timestamp = {2008-09-16T23:40:31.000+0200},
  title = {Backpropagation Applied to Handwritten Zip Code Recognition},
  volume = 1,
  year = 1989
}

@article{attention,
author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Y.},
year = {2014},
month = {09},
pages = {},
title = {Neural Machine Translation by Jointly Learning to Align and Translate},
volume = {1409},
journal = {ArXiv}
}







